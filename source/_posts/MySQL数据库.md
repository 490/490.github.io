---
title: MySQL数据库基础知识
date: 2019-03-09 21:38:30
tags: 数据库
---
索引
事务隔离级别
锁
SQL join
Innodb和MyISAM引擎
MyCAT
<!--more-->
# 索引
数据结构：

**二叉树**：O(logn),深度会深，io多
**B树**：
![image](http://490.github.io/images/20190310_082950.png)
![image](http://490.github.io/images/20190310_082957.png)
**B+树**：底下的链接可做范围统计。磁盘代价低、查询效率稳定、有利于对数据库扫描
![image](http://490.github.io/images/20190310_083024.png)
**Hash**：

innoDB密集索引：每个搜索码值都对应一个索引值
Myisam稀疏索引：只为索引码的某些值建立索引项

**如何定位并优化慢查询sql：**
根据慢日志定位慢查询SQL
使用explain等工具分析SQL
修改SQL或尽量让SQL走索引

* * *

# 事务的隔离级别、锁

[深入理解乐观锁与悲观锁](http://www.hollischuang.com/archives/934)

[事务的隔离级别](http://www.hollischuang.com/archives/943)

## 锁
在关系数据库管理系统里，**悲观并发控制**（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。
悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。

在对任意记录进行修改前，先尝试为该记录加上**排他锁**（exclusive locking）。如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。
其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

上面我们提到，使用`select…for update`会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。

**乐观锁**（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。只能防止脏读后数据的提交，不能解决脏读。
相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。

**行级锁**
开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

**表级锁**
开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

**页级锁**
开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

在不通过索引条件查询的时候,InnoDB 确实使用的是表锁,而不是行锁。
MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。

**行锁**
TODO....
**gap锁**


* * *

![image](http://490.github.io/images/20190310_083531.png)
ANSI/ISO SQL定义的标准隔离级别有四种，从高到底依次为：可序列化(Serializable)、可重复读(Repeatable reads)、提交读(Read committed)、未提交读(Read uncommitted)。

## 未提交读(Read uncommitted)
事务在读数据的时候并未对数据加锁。
事务在修改数据的时候只对数据增加行级共享锁。
所以，未提交读会导致脏读
可以读到其他事务未提交的结果
## 提交读(Read committed)
提交读(READ COMMITTED)也可以翻译成读已提交，通过名字也可以分析出，在一个事务修改数据过程中，如果事务还没提交，其他事务不能读该数据。
提交读的数据库锁情况
事务对当前被读取的数据加 行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；
事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。
简而言之，提交读这种隔离级别保证了读到的任何数据都是提交的数据，避免了脏读(dirty reads)。但是不保证事务重新读的时候能读到相同的数据，因为在每次数据读完之后其他事务可以修改刚才读到的数据。
## 可重复读(Repeatable reads)
事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 行级共享锁，直到事务结束才释放；
事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。
可重复读隔离级别可以解决不可重复读的读现象。但是可重复读这种隔离级别中，还有另外一种读现象他解决不了，那就是幻读。
## 可序列化(Serializable)
事务在读取数据时，必须先对其加 表级共享锁 ，直到事务结束才释放；
事务在更新数据时，必须先对其加 表级排他锁 ，直到事务结束才释放。

* * *

**脏读**

脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。

**不可重复读**

一种更易理解的说法是：在一个事务内，多次读同一个数据。在这个事务还没有结束时，另一个事务也访问该同一数据。那么，在第一个事务的两次读数据之间。由于第二个事务的修改，那么第一个事务读到的数据可能不一样，这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读，即原始读取不可重复。

**幻读**

幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样.一般解决幻读的方法是增加范围锁RangeS，锁定检锁范围为只读，这样就避免了幻读。　　幻读(phantom read)”是不可重复读(Non-repeatable reads)的一种特殊场景：当事务没有获取范围锁的情况下执行SELECT … WHERE操作可能会发生“幻影读(phantom read)”。

当前读、快照读

DB_TRX_ID ，，DB_ROLL_PTR ，， DB_ROW_ID字段

undo日志

* * *

# SQL JOIN

```
Id_P	LastName	FirstName	Address	City
1	Adams	John	Oxford Street	London
2	Bush	George	Fifth Avenue	New York
3	Carter	Thomas	Changan Street	Beijing

Id_O OrderNo Id_P

1     77895 3
2     44678 3
3     22456 1
4     24562 1
5     34764 65
```

SELECT Persons.LastName, Persons.FirstName, Orders.OrderNo
FROM PersonsINNER JOIN Orders
ON Persons.Id_P = Orders.Id_P
ORDER BY Persons.LastName

结果：

LastName FirstName OrderNo
Adams John 22456
Adams John 24562
Carter Thomas 77895
Carter Thomas 44678

在表中存在至少一个匹配时（来自两个表的所有字段都不为空），INNER JOIN 关键字返回行。与 JOIN 是相同的
LEFT JOIN 关键字会从左表 (table_name1) 那里返回所有的行，即使在右表 (table_name2) 中没有匹配的行。 LEFT OUTER JOIN。
SELECT Persons.LastName, Persons.FirstName, Orders.OrderNo
FROM Persons
LEFT JOIN Orders
ON Persons.Id_P=Orders.Id_P
ORDER BY Persons.LastName

LastName	FirstName	OrderNo
Adams	John	22456
Adams	John	24562
Carter	Thomas	77895
Carter	Thomas	44678
Bush	George	 
RIGHT JOIN 关键字会右表 (table_name2) 那里返回所有的行，即使在左表 (table_name1) 中没有匹配的行。只要其中某个表存在匹配，FULL JOIN 关键字就会返回行。
LastName	FirstName	OrderNo
Adams	John	22456
Adams	John	24562
Carter	Thomas	77895
Carter	Thomas	44678
Bush	George	 34764

* * *

# [Innodb与Myisam](https://www.cnblogs.com/changna1314/p/6878900.html)引擎

## 1. 区别：
（1）**事务处理**：
MyISAM是非事务安全型的，而InnoDB是事务安全型的（支持事务处理等高级处理）；
（2）**锁机制不同**：
MyISAM是表级锁，而InnoDB是行级锁；
（3）**select ,update ,insert ,delete 操作**：
MyISAM：如果执行大量的SELECT，MyISAM是更好的选择
InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表
（4）**查询表的行数不同**：
MyISAM：select count(*) from table,MyISAM只要简单的读出保存好的行数，注意的是，当count(*)语句包含   where条件时，两种表的操作是一样的
InnoDB ： InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行
（5）**外键支持**：
mysiam表不支持外键，而InnoDB支持
## 2. 为什么MyISAM会比Innodb 的查询速度快。
INNODB在做SELECT的时候，要维护的东西比MYISAM引擎多很多；
1）数据块，INNODB要缓存，MYISAM只缓存索引块，  这中间还有换进换出的减少； 
2）innodb寻址要映射到块，再到行，MYISAM 记录的直接是文件的OFFSET，定位比INNODB要快
3）INNODB还需要维护MVCC一致；虽然你的场景没有，但他还是需要去检查和维护
MVCC ( Multi-Version Concurrency Control )多版本并发控制 
## 3. 应用场景
MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。
InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。
## MVCC
 [【mysql】关于innodb中MVCC的一些理解](https://www.cnblogs.com/chenpingzhao/p/5065316.html)
通过加锁，让所有的读者等待写者工作完成，但是这样效率会很差。MVCC 使用了一种不同的手段，每个连接到数据库的读者，在某个瞬间看到的是数据库的一个快照，写者写操作造成的变化在写操作完成之前（或者数据库事务提交之前）对于其他的读者来说是不可见的。

innodb存储的最基本row中包含一些额外的存储信息 DATA_TRX_ID，DATA_ROLL_PTR，DB_ROW_ID，DELETE BIT

*   6字节的DATA_TRX_ID 标记了最新更新这条行记录的transaction id，每处理一个事务，其值自动+1

*   7字节的DATA_ROLL_PTR 指向当前记录项的rollback segment的undo log记录，找之前版本的数据就是通过这个指针

*   6字节的DB_ROW_ID，当由innodb自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值，否则聚集索引中不包括这个值.，这个用于索引当中
*   DELETE BIT位用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除。真正意义的删除是在commit的时候

InnoDB的MVCC,是通过在每行记录后面保存两个隐藏的列来实现的,这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间。这里存储的并不是实际的时间值,而是系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID.

**SELECT**
InnoDB会根据以下两个条件检查每行记录: a.InnoDB只会查找版本早于当前事务版本的数据行(也就是,行的系统版本号小于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的. b.行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除. 
只有a,b同时满足的记录，才能返回作为查询结果.
**DELETE**
InnoDB会为删除的每一行保存当前系统的版本号(事务的ID)作为删除标识. 
![image](http://490.github.io/images/20190310_084503.png)

innodb索引和数据在一起

myisam不在一起

* * *
# [MyCAT](http://www.cnblogs.com/joylee/p/7513038.html)

[https://www.jianshu.com/p/21b1e133dd9b](https://www.jianshu.com/p/21b1e133dd9b)
分布式数据库系统中间层

应用场景：需要读写分离，需要分库分表，多租户，数据统计系统，HBASE的一种替代方案

支持全局表
支持ER的分片策略
支持一致性hash分片

![image](http://490.github.io/images/20190310_084553.png)
![image](http://490.github.io/images/20190310_084559.png)

![image](http://490.github.io/images/20190310_084634.png)

**使用MySQL客户端管理mycat**
动态加载配置文件：reload @@config;
查看数据节点：show @@datanode;
查看后端数据库：show @@datasource;


# 复制（replication）和集群（cluster）/读写分离

## Replication

 Replication的思想是将**数据在集群的多个节点同步、备份**，以提高集群数据的**可用性**（HA）；Mysql使用Replication架构来实现上述目的，同时可以**提升了集群整体的并发能力**。。

Replication具有如下优点：

- **扩展**：将负载分布在多个slaves上以提高性能，所有的**writes**以及事务中的**read**操作都将有master处理，其他reads将转发给slaves；对于“读写比”较高的应用，replication可以通过**增加slaves节点来提高并发能力**；因为write只能在master上提交，因此架构扩展对提升write并发能力并不明显，对于writes密集性应用我们应该考虑其他架构。
- **数据安全**：slave可以中断自己的replication进程，这不会打断master上的数据请求，所以可以在slave上运行**backup**服务，定期全量backup是保护数据的手段之一。（如果在master上执行backup，需要让master处于readonly状态，这也意味这所有的write请求需要阻塞）。
- **分析**：数据在master上创建，那么数据分析可以在slave上进行，这将不会影响master的性能。利用mysql做**数据分析**（或者数据分析平台的源数据），通常都是将某个slave作为数据输入端。
- **远距数据分布**：如果master的物理位置较远，你可以在临近需求的地方部署slaves，以便就近使用数据，而不需要总是访问远端的master，这在数据分析、数据备份与容灾等方面有很大帮助。



## Sharding和Replication
1. replication机制的优缺点
- 优点：负载高时可以通过replication机制来提高读写的吞吐和性能。
- 缺点：首先它的有效很依赖于读操作的比例，Master往往会成为瓶颈所在，写操作需要顺序排队来执行，过载的话Master首先扛不住，Slaves的数据同步的延迟也可能比较大，而且会大大耗费CPU的计算能力，因为write操作在Master上执行以后还是需要在每台slave机器上都跑一次。

2. sharding技术的优缺点
- 优点：sharding技术可以弥补replication机制的缺点。因为sharding可以很好的扩展，我们知道每台机器无论配置多么好它都有自身的物理上限，所以当我们应用已经能触及或远远超出单台机器的某个上限的时候，我们惟有寻找别的机器的帮助或者继续升级的我们的硬件，但常见的方案还是横向扩展, 通过添加更多的机器来共同承担压力。我们还得考虑当我们的业务逻辑不断增长，我们的机器能不能通过线性增长就能满足需求？Sharding可以轻松的将计算，存储，I/O并行分发到多台机器上，这样可以充分利用多台机器各种处理能力，同时可以避免单点失败，提供系统的可用性，进行很好的错误隔离。 


## Mysql主从复制的原理

主从复制通过三个过程实现，其一个过程发生在主服务器上，另外两个过程发生在从服务器上。具体情况如下：

主服务器将用户对数据库的**写操作**以二进制格式保存到**Binary Log**（二进制日志）文件中， 然后由**Binlog Dump**线程将二进制日志文件传输给从服务器。

从服务器通过**一个 I/O 线程将主服务器的二进制日志文件中的写操作复制到一个叫 Relay Log 的中继日志文件**中。

从服务器通过**另一个 SQL 线程将 Relay Log 中继日志文件中的写操作依次在本地执行**，从而实现主从服务器之间的数据的同步。

1. BinLog Dump线程

该线程运行在主服务器上，主要工作是把 Binary Log 二进制日志文件的数据发送给从服务器。

使用`SHOW PROCESSLIST`语句，可查看该线程是否正在运行。

2. I/O线程

从服务器执行 `START SLAVE` 语句后，会创建一个 I/O 线程。此线程运行在从服务器上，与主服务器建立连接，然后向主服务器发出同步请求。之后，I/O 线程将主服务器发送的写操作复制到本地 Relay Log 日志文件中。

使用`SHOW SLAVE STATUS`语句，可查看 I/O 线程状态。

3. SQL线程

该线程运行在从服务器上，主要工作是读取 Relay Log 日志文件中的更新操作，并将这些操作依次执行，从而使主从服务器的数据保持同步。

**复制级别**

1. **基于语句的复制**：  在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。  一旦发现没法精确复制时，会自动选着基于行的复制。    

2. **基于行的复制**：把改变的内容复制过去，而不是把命令在从服务器上执行一遍. 从mysql5.0开始支持

3. **混合类型的复制**: 默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。

## Replication的三种常用架构

1. Master - Slaves

在实际应用场景中，MySQL复制90%以上都是一个Master复制到一个或者多个Slave的架构模式，主要用于**读压力比较大的应用的数据库端廉价扩展解决方案**。因为只要Master和Slave的压力不是太大（尤其是Slave端压力）的话，异步复制的延时一般都很少很少。尤其是自从Slave端的复制方式改成两个线程处理之后，更是减小了Slave端的延时问题。而带来的效益是，对于数据实时性要求不是特别严格的应用，只需要通过廉价的pcserver来扩展Slave的数量，将读压力分散到多台Slave的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。

![image](http://490.github.io/images/20190317_094503.png)

2. Master - Master

有些时候，简单的从一个MySQL复制到另外一个MySQL的基本Replication架构，可能还会需要在一些特定的场景下进行Master的切换。如在Master端需要进行一些特别的维护操作的时候，可能需要停MySQL的服务。这时候，为了尽可能减少应用系统写服务的停机时间，最佳的做法就是**将我们的Slave节点切换成Master来提供写入的服务**。

但是这样一来，我们原来Master节点的数据就会和实际的数据不一致了。为了解决这个问题，我们可以通过搭建**DualMaster**环境来避免很多的问题。何谓DualMaster环境？实际上就是两个MySQLServer互相将对方作为自己的Master，自己作为对方的Slave来进行复制。这样，任何一方所做的变更，都会通过复制应用到另外一方的数据库中。

可能有些读者朋友会有一个担心，这样搭建复制环境之后，难道不会造成两台MySQL之间的循环复制么？实际上MySQL自己早就想到了这一点，所以在MySQL的**BinaryLog**中记录了当前MySQL的server-id，而且这个参数也是我们搭建MySQLReplication的时候必须明确指定，而且Master和Slave的server-id参数值比需要不一致才能使MySQLReplication搭建成功。一旦有了server-id的值之后，MySQL就很容易判断某个变更是从哪一个MySQLServer最初产生的，所以就很容易避免出现循环复制的情况。而且，如果我们不打开记录Slave的BinaryLog的选项（--log-slave-update）的时候，MySQL根本就不会记录复制过程中的变更到BinaryLog中，就更不用担心可能会出现循环复制的情形了。下如将更清晰的展示DualMaster复制架构组成：

![image](http://490.github.io/images/20190317_094555.png)

通过DualMaster复制架构，我们不仅能够避免因为正常的常规维护操作需要的停机所带来的重新搭建Replication环境的操作，因为我们任何一端都记录了自己当前复制到对方的什么位置了，当系统起来之后，就会自动开始从之前的位置重新开始复制，而不需要人为去进行任何干预，大大节省了维护成本。

不仅仅如此，DualMaster复制架构和一些第三方的HA管理软件结合，还可以在我们**当前正在使用的Master出现异常无法提供服务之后，非常迅速的自动切换另外一端来提供相应的服务，减少异常情况下带来的停机时间**，并且完全不需要人工干预。

当然，我们搭建成一个DualMaster环境，并不是为了让两端都提供写的服务。在正常情况下，我们都只会将其中一端开启写服务，另外一端仅仅只是提供读服务，或者完全不提供任何服务，仅仅只是作为一个备用的机器存在。为什么我们一般都只开启其中的一端来提供写服务呢？主要还是为了**避免数据的冲突，防止造成数据的不一致性**。因为即使在两边执行的修改有先后顺序，但由于Replication是**异步的实现机制（CAP）**，同样会导致即使晚做的修改也可能会被早做的修改所覆盖。

3. Master –Slaves - Slaves

在有些应用场景中，可能读写压力差别比较大，读压力特别的大，一个Master可能需要上10台甚至更多的Slave才能够支撑注读的压力。这时候，Master就会比较吃力了，因为仅仅连上来的SlaveIO线程就比较多了，这样写的压力稍微大一点的时候，Master端因为复制就会消耗较多的资源，很容易造成复制的延时。

遇到这种情况如何解决呢？这时候我们就可以利用MySQL可以在Slave端记录复制所产生变更的BinaryLog信息的功能，也就是打开—log-slave-update选项。然后，通**过二级（或者是更多级别）复制来减少Master端因为复制所带来的压力**。也就是说，我们首先通过少数几台MySQL从Master来进行复制，这几台机器我们姑且称之为**第一级Slave集群**，然后其他的Slave再从第一级Slave集群来进行复制。从第一级Slave进行复制的Slave，我称之为**第二级Slave集群**。如果有需要，我们可以继续往下增加更多层次的复制。这样，我们很容易就控制了每一台MySQL上面所附属Slave的数量。这种架构我称之为Master-Slaves-Slaves架构

这种多层级联复制的架构，很容易就解决了Master端因为附属Slave太多而成为瓶颈的风险。下图展示了多层级联复制的Replication架构。

![image](http://490.github.io/images/20190317_094656.png)

## 读写分离

读写分离，基本的原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作。数据库复制被用来把事务性操作导致的变更同步到集群中的从数据库。

读写分离的好处：

1. 增加冗余
2. 增加了机器的处理能力
3. 对于读操作为主的应用，使用读写分离是最好的场景，因为可以确保写的服务器压力更小，而读又可以接受点时间上的延迟。

读写分离在实现上一般采用复制的方式，读在Slave端，写和事务在Master端，按照其实现可分为如下两种大类：

1. 程序修改mysql操作类

在数据库操作时直接指定读写库的位置，这种方式
- 优点：直接和数据库通信，简单快捷的读写分离和随机的方式实现的负载均衡，权限独立分配
- 缺点：数据段和程序的耦合度太高，自己维护更新，增减服务器在代码处理。

2. 数据库代理

使用mysql官方（mysql proxy）或者第三方数据库代理（如mycat）将数据库连接抽象和屏蔽，
- 优点：直接实现读写分离和负载均衡，不用修改代码，
- 缺点：增加额外耗时和性能损耗。


## Replication的常用方案

1. master-master架构

两台服务器装mysql，各自作为对方的从机接受对方发来的数据，做到数据的同步备份，感觉和master-slave基本实现原理是一样的。这样保证了数据的一致性，如何保证其中一台服务器故障，自动切换到另外的一个master上呢，[使用MMM(MySQL Master-Master Replication Manager)来管理](http://liuyu.blog.51cto.com/183345/98867/)。

2. heartbeat+drbd+mysql主从复制

基本原理与1相似，这里需要做一个master库的冗余备份，使用**drbd**来保证不同服务器中两个master库的数据一致性。利用**heartbeat**来完成其中一台服务器发生故障后的自动切换。结构如下图：

![image](http://490.github.io/images/20190317_094901.png)

3. Mysql + keepalived 实现双主热备读写分离

keepalived主要用于实现故障切换和热备，作为mysql的补充。

![image](http://490.github.io/images/20190317_094926.png)



# NDB Cluster

MySQL NDB Cluster是一个适用于分布式计算环境的高可用性、高冗余版本的MySQL。
NDB集群由一组计算机组成，称为主机，每个计算机运行一个或多个进程。这些进程称为节点，可能包括MySQL服务器（用于访问NDB数据）、数据节点（用于存储数据）、一个或多个管理服务器，以及可能的其他专门的数据访问程序。在NDB集群中这些组件的关系如下所示：

![image](http://490.github.io/images/20190318_083546.png)

所有这些程序一起工作来形成一个NDB集群。当数据被NDB存储引擎存储时，表（和表数据）存储在数据节点中。这样的表可以直接从集群中的所有MySQL服务器（SQL节点）访问。因此，在一个将数据存储在集群中的工资单应用程序中，如果一个应用程序更新了雇员的工资，那么查询这些数据的所有其他MySQL服务器都可以立即看到这个变化。

作者：季舟1
链接：https://www.jianshu.com/p/c989ee86d7cf
来源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。


NDB CLUSTER（也称为NDB）是一个内存存储引擎，提供高可用的数据持久化功能。
NDB CLUSTER存储引擎可以配置一系列故障转移和负载平衡。

## 集群节点

集群节点有三种类型，在最小的NDB集群配置中，至少会有三个节点。

### Management node

这种类型节点的作用是管理NDB集群中的其他节点，执行诸如提供配置数据、启动和停止节点以及运行备份等功能。因为这个节点类型管理其他节点的配置，所以应该首先启动这种类型的节点，在任何其他节点之前。执行ndb_mgmd命令启动该节点。

### Data node

这种类型节点的作用是存储集群数据。一个副本足以用于数据存储，但不提供冗余;因此，建议使用2（或更多）副本来提供冗余，从而获得高可用性。执行ndbd或ndbmtd（多线程）命令启动该节点。NDB集群表通常存储在内存中，而不是在磁盘上（这就是为什么我们将NDB集群称为内存中的数据库）。然而，一些NDB集群数据可以存储在磁盘上。

###  SQL node

在NDB Cluster中SQL节点是一个使用NDBCLUSTER存储引擎的传统MySQL服务器。

期望在生产环境中使用三个节点的设置是不现实的。这样的配置不提供冗余;为了从NDB集群的高可用性特性中获益，您必须使用多个数据和SQL节点。还强烈推荐使用多个管理节点。

## 客户端

###  标准MySQL客户端

NDB集群可以与用PHP、Perl、C、C++、Java、Python、Ruby等编写的现有MySQL应用程序一起使用。这样的客户端应用程序发送SQL语句并接收来自MySQL服务器的响应，它们充当NDB集群SQL节点，就像它们与独立的MySQL服务器交互一样。例如，使用Connector/J 5.0.6和更高版本的Java客户端可以使用jdbc:mysql:loadbalance://url以透明地实现负载平衡。

###  NDB客户端

客户端程序可以使用NDB API（一个高层次的C++ API，NDBCLUSTER存储引擎）直接访问NDB集群数据，绕过任何可能连接到集群的MySQL服务器。
对于NDB集群来说，也可以使用NDB集群连接器来为NDB集群编写Java应用程序。NDB集群连接器包括ClusterJ，这是一种类似于对象关系映射持久性框架的高级数据库API，如Hibernate和JPA，它们直接连接到NDBCLUSTER，因此不需要访问MySQL服务器。在NDB集群中也为ClusterJPA提供了支持，这是一个利用ClusterJ和JDBC的优势的NDB集群的OpenJPA实现。ID查找和其他快速操作是使用ClusterJ（绕过MySQL服务器）执行的，而可以从MySQL查询优化器中获益的更复杂的查询是通过MySQL服务器发送的，使用JDBC。

### 管理客户端

这些客户端连接到管理服务器，并提供启动和停止节点的命令，启动和停止消息追踪（仅调试版本），显示节点版本和状态，启动和停止备份，等等。这种类型的程序的一个例子是ndbmgm管理客户端提供的NDB集群。

### 检查点

 一般来说，当数据保存到磁盘时，据说已到达检查点。 更具体的是NDB Cluster，检查点是所有已提交事务存储在磁盘上的时间点。 关于NDB存储引擎，有两种类型的检查点可以协同工作，以确保维护集群数据的一致视图。 这些显示在以下列表中：

- 本地检查点（LCP）：这是一个特定于单个节点的检查点; 但是，LCP或多或少同时发生在集群中的所有节点上。 LCP通常每隔几分钟发生一次; 精确的间隔会有所不同，并取决于节点存储的数据量，群集活动的级别以及其他因素。
在NDB 7.6.4之前，LCP涉及将所有节点的数据保存到磁盘。 NDB 7.6.4引入了对部分LCP的支持，在某些条件下可以显着提高恢复时间。 有关更多信息，请参见第21.1.4.2节“NDB Cluster 7.6中的新增功能”，以及启用部分LCP并控制其使用的存储量的EnablePartialLcp和RecoveryWork配置参数的说明。

- 全局检查点（GCP）：每隔几秒就会发生一次GCP，此时所有节点的事务都已同步，并且重做日志被刷新到磁盘。
- 
## Nodes, Node Groups, Replicas, and Partitions


**Data Node。** ndbd或ndbmtd进程，用于存储一个或多个副本，即分配给该节点所属的节点组的分区副本（本节稍后讨论）。

每个数据节点应位于单独的计算机上。 虽然也可以在一台计算机上托管多个数据节点进程，但通常不建议这样的配置。

当引用ndbd或ndbmtd进程时，术语“节点”和“数据节点”通常可互换使用; 如上所述，管理节点（ndb_mgmd进程）和SQL节点（mysqld进程）在本讨论中如此指定。

**Node group。**节点组由一个或多个节点组成，并存储分区或副本集（请参阅下一项）。

NDB群集中的节点组数量不能直接配置; 它是数据节点数和副本数（NoOfReplicas配置参数）的函数，如下所示：`# of node groups = # of data nodes / NoOfReplicas`


**Partition。** 这是群集存储的数据的一部分。 每个节点负责保留分配给它的任何分区的至少一个副本（即，至少一个副本）。
NDB Cluster默认使用的分区数取决于数据节点的数量和数据节点使用的LDM线程数，如下所示：`[# of partitions] = [# of data nodes] * [# of LDM threads]`

使用运行ndbmtd的数据节点时，LDM线程的数量由MaxNoOfExecutionThreads的设置控制。 使用ndbd时，只有一个LDM线程，这意味着与参与集群的节点一样多的集群分区。 使用ndbmtd且MaxNoOfExecutionThreads设置为3或更小时也是如此。 （您应该知道LDM线程的数量随着此参数的值而增加，但不是严格线性的，并且设置它有其他限制;有关详细信息，请参阅MaxNoOfExecutionThreads的说明。）

**NDB and user-defined partitioning**。 NDB群集通常会自​​动分区NDBCLUSTER表。但是，也可以使用NDBCLUSTER表进行用户定义的分区。这受到以下限制：

1. 使用NDB表生产时仅支持KEY和LINEAR KEY分区方案。
2. 可以为任何NDB表显式定义的最大分区数是8 * MaxNoOfExecutionThreads * [节点组数]，NDB群集中的节点组数量正如本节前面所讨论的那样确定。使用ndbd进行数据节点进程时，设置MaxNoOfExecutionThreads无效;在这种情况下，为了执行该计算，可以将其视为等于1。

**Replica**。 这是群集分区的副本。 节点组中的每个节点都存储一个副本。 有时也称为分区副本。 副本数等于每个节点组的节点数。

副本完全属于单个节点; 节点可以（通常会）存储多个副本。

下图说明了一个NDB集群，其中四个数据节点运行ndbd，分别安排在两个节点组中，每个节点组包含两个节点; 节点1和2属于节点组0，节点3和4属于节点组1。这里只显示数据节点; 虽然有效的NDB群集需要ndb_mgmd进程进行群集管理，并且至少有一个SQL节点需要访问群集存储的数据，但为清楚起见，这些已从图中省略。

![image](http://490.github.io/images/20190318_133536.png)

群集存储的数据分为四个分区，编号为0,1,2和3.每个分区在同一节点组中存储多个副本。分区存储在备用节点组中，如下所示：

- 分区0存储在节点组0上;主副本（主副本）存储在节点1上，备份副本（分区的备份副本）存储在节点2上。
- 分区1存储在另一个节点组（节点组1）上;此分区的主副本位于节点3上，其备份副本位于节点4上。
- 分区2存储在节点组0上。但是，它的两个副本的放置与分区0的放置相反;对于分区2，主副本存储在节点2上，备份存储在节点1上。
- 分区3存储在节点组1上，并且其两个副本的放置与分区1的位置相反。即，其主副本位于节点4上，备份在节点3上。

对于NDB集群的持续运行，这意味着：只要参与集群的每个节点组至少有一个节点运行，集群就拥有所有数据的完整副本并且仍然可行。这将在下图中说明。

![image](http://490.github.io/images/20190318_133608.png)

在此示例中，群集由两个节点组组成，每个节点组由两个数据节点组成。 每个数据节点都运行ndbd的实例。 来自节点组0的至少一个节点和来自节点组1的至少一个节点的任何组合足以使群集保持“活动”。 但是，如果来自单个节点组的两个节点都发生故障，则由另一个节点组中的其余两个节点组成的组合是不够的。 在这种情况下，群集已丢失整个分区，因此无法再提供对所有NDB群集数据的完整集合的访问。

在NDB 7.5.4和更高版本中，单个NDB群集实例支持的最大节点组数为48（Bug＃80845，Bug＃22996305）。

## Network communication and latency


NDB Cluster需要数据节点和API节点（包括SQL节点）之间以及数据节点和其他数据节点之间的通信，以执行查询和更新。这些进程之间的通信延迟可直接影响观察到的用户查询的性能和延迟。此外，为了在节点无声故障的情况下保持一致性和服务，NDB Cluster使用**心跳和超时机制**，将来自节点的通信的延长丢失视为节点故障。这可以减少冗余。回想一下，为了保持数据一致性，当节点组中的最后一个节点发生故障时，NDB集群会关闭。因此，为了避免增加强制关闭的风险，应尽可能避免节点之间的通信中断。

数据或API节点的故障导致涉及故障节点的所有未提交事务的中止。数据节点恢复需要在数据节点恢复服务之前，从幸存的数据节点同步故障节点的数据，并重新建立基于磁盘的重做和检查点日志。此恢复可能需要一些时间，在此期间群集以减少的冗余运行。

心跳依赖于所有节点及时生成心跳信号。如果节点过载，由于与其他程序共享导致机器CPU不足，或者由于交换而出现延迟，则可能无法执行此操作。如果心跳生成被充分延迟，则其他节点会将响应缓慢的节点视为失败。

在某些情况下，将慢节点作为故障节点的这种处理可能是或可能不是合乎需要的，这取决于节点的慢速操作对集群其余部分的影响。为NDB群集设置HeartbeatIntervalDbDb和HeartbeatIntervalDbApi等超时值时，必须注意实现快速检测，故障转移和恢复服务，同时避免可能出现的代价高昂的误报。

如果预期数据节点之间的通信延迟高于LAN环境中预期的通信延迟（大约100μs），则必须增加超时参数以确保任何允许的延迟时段都在配置的超时内。以这种方式增加超时对于检测故障的最坏情况时间以及因此服务恢复的时间具有相应的影响。

LAN环境通常可以配置稳定的低延迟，并且可以通过快速故障转移提供冗余。可以从TCP级别可见的最小和受控延迟（NDB群集正常运行）中恢复单个链路故障。 WAN环境可能会提供一系列延迟，以及冗余和较慢的故障转移时间。单个链路故障可能需要在端到端连接恢复之前传播路由更改。在TCP级别，这可能表现为各个通道上的大延迟。在这些情况下观察到的最坏情况的TCP延迟与IP层在故障周围重新路由的最坏情况时间有关。

